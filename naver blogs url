'''
네이버 브랜드 검색 --> 블로그 url 찾기 --> 파
'''

import requests
from bs4 import BeautifulSoup
import time

NAVER_SERCH1='https://m.search.naver.com/search.naver?where=m_blog&sm=mtb_pge&query='
NAVER_SERCH2='&display=15&st=sim&nso=&start='
NAVER_DISPLAYNO=15    #네이버 검색결과 페이지 하나당 블로그 15개 표시
BLOGS_NO=300     # 한 검색어 당 블로그 조회수 (15 배수로 지정하는 것이 좋음)
SEARCH_WORDS= ['설화수','헤라','라네즈','마몽드','려','미쟝센','해피바스','에스티로드', \
               '후','YSL', 'Dior', '크리니크', '비오템', '더페이스샵', 'AHC', '리엔', '엘라스틴', '온더바디']
  

def make_search_pageurl(word, page_no):
    '''
    검색어와 검색 페이지 번호 입력 --> 해당 검색결과 페이지 url     
    '''    
    pageurl=NAVER_SERCH1+word+NAVER_SERCH2+str(page_no*NAVER_DISPLAYNO)
    
    return pageurl


def get_blogs_url(word):
    '''
    검색어 입력 --> 검색된 블로그 url 주소 
    '''
    
    blogs_urls=[]
    for page_no in range(1,int(BLOGS_NO/15)+1):
        url=make_search_pageurl(word,page_no)  
        html=get_html(url)
        soup=BeautifulSoup(html,"lxml")
        blogs_links=soup.find("ul", attrs={'class':'lst_total', 'id':'addParemt'})
        for blogs_link in blogs_links.find_all('a'):
            url=blogs_link['href']
            blogs_urls.append(url)
        time.sleep(0.7)
    time.sleep(0.7)
    return blogs_urls


def make_output_file(word):
    '''
    검색결과를 저장할 파일명을 생성한다
    '''
    outputfile="./naverblogs/NaverSearchResult_"+word+".txt"
    
    return outputfile
    

for word in SEARCH_WORDS:
    pageurls=get_blogs_url(word)
    print(word, len(pageurls))
    outputfile=make_output_file(word)
    with open(outputfile, "w", encoding="utf-8") as output_file:
        for pageurl in pageurls:
            print(pageurl, file=output_file)
